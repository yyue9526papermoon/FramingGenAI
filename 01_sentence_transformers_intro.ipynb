{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd8723b-0fd3-4c5a-96b6-96ab7b1cf68e",
   "metadata": {},
   "source": [
    "# Sentence-Transformers — Intro Practice\n",
    "\n",
    "**Goal.** This notebook practices the core workflow of `sentence-transformers`:\n",
    "1) load a pre-trained sentence embedding model,\n",
    "2) encode short news-like sentences,\n",
    "3) compute cosine similarities and run semantic search (Top-K),\n",
    "4) cluster embeddings with KMeans.\n",
    "\n",
    "**Model.** `sentence-transformers/all-MiniLM-L6-v2` (384-dim; small & fast).\n",
    "\n",
    "**How to run.**\n",
    "- Kernel: `Python (framing-py310)`\n",
    "- Dependencies: see `requirements.txt`\n",
    "- Execute the three code cells in order: Load → Similarity/Search → Clustering.\n",
    "\n",
    "**Expected outputs.**\n",
    "- Embedding shape like `(6, 384)`\n",
    "- A 6×6 cosine similarity matrix\n",
    "- Top-K search results for the query “Central bank hikes rates again.”\n",
    "- KMeans cluster IDs showing ~3 themes (economy, technology, sports).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be1ad430-bde1-4458-b19e-51bc3b518d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\download\\envs\\framing-py310\\python.exe\n",
      "sentence-transformers installed? True\n"
     ]
    }
   ],
   "source": [
    "import sys, pkgutil\n",
    "print(sys.executable)  # path should include \\envs\\framing-py310\\python.exe\n",
    "print(\"sentence-transformers installed?\",\n",
    "      pkgutil.find_loader(\"sentence_transformers\") is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe82fab-dd1b-48e1-a8ed-9d61ff7c32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice with sentence-transformers: load a small, fast model and encode a tiny corpus.\n",
    "# Model choice: \"all-MiniLM-L6-v2\" is lightweight (384-dim) and good for demos on CPU.\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ca13d2-6473-4b94-be5b-a532689f769b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02ff7524dbd45df8176d6e725f4a676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\download\\envs\\framing-py310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\CoCo\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4737720c0fca490993c2e566cedcd062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663de93300fb43abb7aad90c81413010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2f8fc664fb46439f0ed2ca67426f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eccad5ce82164636be6888fdf2358b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2711793a4cee4d91933d5f65935ac645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1928ce87ed54eae926f4a36e42cc637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2657e69181bc4e8a8e2f29304ce9f1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5c5d925ea648b7849f93b75a07d73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9abb27a4cce478fb354850dd1ed8887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b6bc5895ef4ef6b49e68494fd6406d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Load the sentence-embedding model (downloads on first use).\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b1340d5-f2af-41d9-b8fe-34f4c40cd6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) A tiny toy corpus of news-like sentences across different topics.\n",
    "sentences = [\n",
    "    \"The Federal Reserve raised interest rates again.\",\n",
    "    \"Stocks fell on inflation worries.\",\n",
    "    \"Apple unveils the new iPhone.\",\n",
    "    \"Google announces an AI laptop chip.\",\n",
    "    \"Real Madrid wins the derby.\",\n",
    "    \"Olympic committee adds a new sport.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6195aedc-8b76-4a9c-bfb4-898d8c7be8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape (num_sentences, dim): (6, 384)\n",
      "Device: CPU\n"
     ]
    }
   ],
   "source": [
    "# 3) Encode all sentences into embeddings (vectors).\n",
    "#    - convert_to_tensor=True: returns a PyTorch tensor for fast similarity ops.\n",
    "#    - normalize_embeddings=True: L2-normalizes vectors (cosine similarity becomes dot product).\n",
    "embeddings = model.encode(\n",
    "    sentences,\n",
    "    convert_to_tensor=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "print(\"Embeddings shape (num_sentences, dim):\", tuple(embeddings.shape))\n",
    "print(\"Device:\", \"CUDA\" if torch.cuda.is_available() else \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad05d2a-f2a1-43a7-a910-6b75ef1d4c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (A) compute pairwise cosine similarities among the 6 sentences\n",
    "# (B) run a semantic search: given a query, find the Top-K most similar sentences\n",
    "\n",
    "from sentence_transformers import util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2628bdaa-782a-4bfb-ae9b-093732223eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise cosine similarity matrix (rounded to 3 decimals):\n",
      "['1.000', '0.307', '0.233', '0.092', '-0.070', '0.167']\n",
      "['0.307', '1.000', '0.085', '0.006', '-0.074', '-0.060']\n",
      "['0.233', '0.085', '1.000', '0.307', '0.021', '0.193']\n",
      "['0.092', '0.006', '0.307', '1.000', '-0.021', '0.131']\n",
      "['-0.070', '-0.074', '0.021', '-0.021', '1.000', '0.147']\n",
      "['0.167', '-0.060', '0.193', '0.131', '0.147', '1.000']\n"
     ]
    }
   ],
   "source": [
    "# (A) Pairwise cosine similarity matrix (6x6). Higher value => more similar.\n",
    "sim_matrix = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "print(\"Pairwise cosine similarity matrix (rounded to 3 decimals):\")\n",
    "for i in range(sim_matrix.size(0)):\n",
    "    row = [f\"{float(sim_matrix[i, j]):.3f}\" for j in range(sim_matrix.size(1))]\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9af5af5-4555-4816-8293-c1c3b78ee3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Central bank hikes rates again.\n",
      "Top-3 results (score -> sentence):\n",
      "0.754 -> The Federal Reserve raised interest rates again.\n",
      "0.213 -> Apple unveils the new iPhone.\n",
      "0.195 -> Stocks fell on inflation worries.\n"
     ]
    }
   ],
   "source": [
    "# (B) Semantic search (Top-K): encode the query and retrieve the K most similar sentences\n",
    "query = \"Central bank hikes rates again.\"\n",
    "q_emb = model.encode(query, convert_to_tensor=True, normalize_embeddings=True)\n",
    "\n",
    "top_k = 3\n",
    "hits = util.semantic_search(q_emb, embeddings, top_k=top_k)[0]\n",
    "\n",
    "print(\"\\nQuery:\", query)\n",
    "print(f\"Top-{top_k} results (score -> sentence):\")\n",
    "for h in hits:\n",
    "    print(f\"{h['score']:.3f} -> {sentences[h['corpus_id']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1fa10-c36a-477f-9a9e-52dcb637d635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490cfe0-911e-4865-9fc3-c358a4030ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d19a91f8-a9aa-4890-8ad6-5791386f0ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering groups similar sentences together WITHOUT labels.\n",
    "# We use KMeans with K=3 (roughly: economy, technology, sports).\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04557cbc-3b6a-4c50-9e92-9a3211e14ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Convert embeddings to NumPy (scikit-learn expects NumPy arrays).\n",
    "X = embeddings.detach().cpu().numpy()\n",
    "\n",
    "# 2) Run KMeans with a fixed random_state for reproducibility.\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\").fit(X)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6af50e0-0e57-4a03-8ad9-dee2740c3f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans clustering with K=3:\n",
      "[cluster 0] Apple unveils the new iPhone.\n",
      "[cluster 0] Google announces an AI laptop chip.\n",
      "[cluster 0] Olympic committee adds a new sport.\n",
      "[cluster 1] Real Madrid wins the derby.\n",
      "[cluster 2] Stocks fell on inflation worries.\n",
      "[cluster 2] The Federal Reserve raised interest rates again.\n"
     ]
    }
   ],
   "source": [
    "# 3) Print cluster assignment for each sentence.\n",
    "print(f\"KMeans clustering with K={k}:\")\n",
    "for lab, sent in sorted(zip(labels, sentences), key=lambda x: (x[0], x[1])):\n",
    "    print(f\"[cluster {lab}] {sent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b09dbe-9456-41aa-9610-a0675ca6ed9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Centroid-to-sentence cosine similarities (rounded):\n",
      "cluster 0: 0.238, 0.015, 0.727, 0.696, 0.071, 0.641\n",
      "cluster 1: -0.070, -0.074, 0.021, -0.021, 1.000, 0.147\n",
      "cluster 2: 0.809, 0.809, 0.197, 0.061, -0.089, 0.066\n"
     ]
    }
   ],
   "source": [
    "# 4) (Optional) Inspect how \"central\" each sentence is to each cluster via centroid similarity.\n",
    "centroids = kmeans.cluster_centers_  # shape: (k, dim)\n",
    "centroids = centroids / np.linalg.norm(centroids, axis=1, keepdims=True)  # L2-normalize\n",
    "\n",
    "print(\"\\nCentroid-to-sentence cosine similarities (rounded):\")\n",
    "for ci, c in enumerate(centroids):\n",
    "    sims = np.dot(X, c)  # dot product == cosine because both sides are normalized\n",
    "    sims_str = \", \".join(f\"{float(s):.3f}\" for s in sims)\n",
    "    print(f\"cluster {ci}: {sims_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d221fce-b05f-42f8-b24f-1e368cfc96a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (framing-py310)",
   "language": "python",
   "name": "framing-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
